{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM15oyG2K2MQ3n9FVlxlSuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nauboys/model_fafstai/blob/master/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YclKywi0vWm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89aFsQ7JvZ4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3f76b6a2-e9db-4ccf-d281-cb33a7a1bfa0"
      },
      "source": [
        "df_imdb = pd.read_csv('IMDB Dataset.csv')\n",
        "df_imdb.head()#Loading only few training and validation samples, for quick training time\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N3WtzuTvghP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_texts = df_imdb.loc[10000:14999, 'review'].values\n",
        "trn_labels = df_imdb.loc[10000:14999, 'sentiment'].values\n",
        "val_texts = df_imdb.loc[36000:38999, 'review'].values\n",
        "val_labels = df_imdb.loc[36000:38999, 'sentiment'].values\n",
        "np.random.seed(42)\n",
        "trn_idx = np.random.permutation(len(trn_texts))\n",
        "val_idx = np.random.permutation(len(val_texts))\n",
        "trn_texts = trn_texts[trn_idx]\n",
        "val_texts = val_texts[val_idx]\n",
        "trn_labels = trn_labels[trn_idx]\n",
        "val_labels = val_labels[val_idx]\n",
        "col_names = ['labels','text']\n",
        "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
        "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40tM4lsyvo2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "629d8e3b-eb06-46f1-ac4d-737e3bee1971"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df('./', train_df=df_trn, valid_df=df_val)\n",
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>) is desperate to move east , and to see him selling his spread to xxmaj lee xxmaj wilkison ( xxmaj edward xxup g. xxmaj robinson ) . \\n \\n  xxmaj parrish is not even much of a xxunk   but he do understand that there is something big building up in the valley   xxmaj in the xxmaj army , they used to call it '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>have a short walk - on role . xxmaj but somehow they manage to keep xxmaj morgan xxmaj freeman as xxmaj god . xxmaj while sitting in the near empty theater bored out of my mind at the lack of comedy i could n't help but wonder how much money it took to secure xxmaj freeman for this film . xxmaj then it hit me an hour ago . xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>'s supremely well done and captivating viewing throughout : the best film from this director that i 've seen , and among the very best of its genre . xxbos xxmaj here 's why this movie fell very short of its xxunk do n't read much , so i do n't care xxup what the novel was like ) . 1 . i think xxmaj brendan xxmaj frasier copied his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>'s a shame , because there was a lot of talent , both musically and otherwise , in xxmaj the xxmaj monkees . xxmaj it 's probably odder that xxmaj rafelson , who directs here and co - produces with xxmaj schneider , and xxmaj jack xxmaj nicholson ( yes , _ that _ xxmaj jack xxmaj nicholson ) , who wrote the script and also co - produces ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>again . xxmaj only after you see the closing credits do you get an idea of who is who . xxmaj after you know that you can watch it again with renewed appreciation . xxmaj do n't listen to the people that tear this movie apart . xxmaj it 's not for everyone . xxmaj if you 're someone that does n't like reading subtitles than this movie is n't</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpszbPBmvqzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('tmp_lm')\n",
        "data_lm = load_data('./', 'tmp_lm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-KWl9Uivr3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1JqusYTvsVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.lr_find"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EoYJcTTvuUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "5277e80f-1433-48b9-ca55-2bab01c612af"
      },
      "source": [
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/336 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-dfd2171f1eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_distrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, from_embeddings)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mnew_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnew_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#To avoid the warning that comes because the weights aren't flattened.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxhoXXv5vyfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.unfreeze()\n",
        "learner.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UiTgA1vz8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save_encoder('fine_enc')\n",
        "# data_clas = TextClasDataBunch.from_df('./', train_df=df_trn, valid_df=df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4zjFDOfv7Fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTsm_9wxg_CA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d4ae0959-4902-4397-8534-3373c56b71ea"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df('./', train_df=df_trn, valid_df=df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nne5qSw3hBQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4067f8e-0a82-4879-96ea-c458c7a2e265"
      },
      "source": [
        "classifier = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)\n",
        "classifier.load_encoder('fine_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5000 items)\n",
              "x: TextList\n",
              "xxbos \" xxmaj the xxmaj violent xxmaj men \" marked the finest collaboration of xxmaj rudolph xxmaj xxunk with xxmaj glenn xxmaj ford in an intensely satisfying drama of rugged primitive justice \n",
              " \n",
              " \n",
              "  xxmaj ford is xxmaj john xxmaj parrish , a former xxmaj cavalry captain who is xxunk to get married and start a new life \n",
              "  xxmaj his fiancée xxmaj caroline xxmaj xxunk ( xxmaj may xxmaj wynn ) is desperate to move east , and to see him selling his spread to xxmaj lee xxmaj wilkison ( xxmaj edward xxup g. xxmaj robinson ) . \n",
              " \n",
              "  xxmaj parrish is not even much of a xxunk \n",
              "  but he do understand that there is something big building up in the valley \n",
              "  xxmaj in the xxmaj army , they used to call it ' enemy pressure . ' xxmaj first , xxmaj cole xxmaj wilkison ( xxmaj brian xxmaj keith ) comes back from xxmaj texas to help his brother run xxmaj anchor \n",
              "  xxmaj then a tough kid with a fancy gun ( xxmaj richard xxmaj jaeckel ) shows up on the xxmaj wilkison payroll \n",
              "  xxmaj then all the small ranchers are forced out , getting the same kind of offers \n",
              "  xxmaj parrish saw himself either running like they did , or stand and fight \n",
              " \n",
              " \n",
              "  xxmaj but can he easily deals with a man who sends six killers to shoot an old man in the back ? xxmaj can he easily argues with a man who started with a few acres of land and now owns practically the whole valley ? \n",
              " \n",
              "  xxmaj all that grass and sand ever meant to the ex - xxmaj confederate xxmaj army officer the past three years \n",
              "  xxmaj it was a place to regain his health \n",
              "  xxmaj out of habit of taking advice , xxmaj parrish xxunk : \" xxmaj what happen in this valley is no concern of mine . \" xxmaj and much to the disappointment of the remaining ranchers and farmers , who pressure him to stay on , he decides to accept xxmaj wilkison 's offer to fulfill the promise he made to his fiancée \n",
              " \n",
              " \n",
              "  xxmaj when xxmaj lee 's younger brother xxmaj cole made the wrong move , trying to push xxmaj parrish make up his mind by lynching one of his ranch hands , xxmaj parrish got mad and warns the two brothers that he is going to stay and will fight them for the privilege of being let alone \n",
              " \n",
              " \n",
              "  xxmaj brian xxmaj keith plays the traitorous brother who 's behind the killing ... xxmaj he dreams to have position and respect in running one day xxmaj anchor \n",
              " \n",
              " \n",
              "  xxmaj lee 's ambitious wife xxmaj martha ( xxmaj barbara xxmaj stanwyck ) secretly hates herself and her husband \n",
              "  xxmaj stanwyck plays the part of a loving wife who ca n't bear the touch of her husband 's hands \n",
              " \n",
              " \n",
              "  xxmaj edward xxup g. xxmaj robinson is good enough as the xxmaj anchor 's crippled owner who promised the whole valley to his wife , unaware that she is having an affair with his younger brother \n",
              " \n",
              " \n",
              "  xxmaj dianne xxmaj foster is too sensitive as the xxunk adult daughter well aware of her mother 's burdens \n",
              " \n",
              " \n",
              "  \" xxmaj the xxmaj violent xxmaj men \" uses the wide - screen technology to emphasize the scope and power of this harrowing action - drama , making it a perfect example of the genre 's most enduring classics \n",
              ",xxbos xxmaj plants in an ancient xxmaj mayan pyramid structure killing all who come close . xxmaj yes it is weird , as the travelers do not figure it out until everything starts doing crazy . xxmaj and in a movie like this , i just wished it went absurd and had marching bands being attacked by plants wielding xxunk . \n",
              " \n",
              "  xxmaj anyway , a group of people from xxmaj america vacation and go into the mountains with a couple of other newly made xxmaj german friends who know about the place . xxmaj when they get there , xxmaj mayans began shouting at them and hide on the structure . xxmaj and when there , that s when the plants decide to take them out , mimicking cell phone noises , humans , and ancient xxmaj mayan dead people . \n",
              " \n",
              "  xxmaj nothing was really scary about the movie and was not even entertaining . xxmaj not even the weird ending could save this piece of crap . i kept looking for something really good to happen , but nothing . xxmaj oh well . \" f \",xxbos xxmaj true , there are many movies much worse then this movie . xxmaj this movie was no xxmaj manos : xxmaj the xxmaj hands of xxmaj fate , or xxmaj troll 2 ( yes , i have seen them both .. twice ) but at the same time this movie is xxmaj no xxmaj alien , xxmaj predator or even xxmaj alien xxmaj vs . xxmaj predator ( xxmaj yes , even that movie surpassed this ) . xxmaj movies like this make xxmaj battlefield xxmaj earth look like a xxmaj star xxmaj wars it is so bad . xxmaj razzie awards lookout , your biggest competition has just arrived in theaters . xxmaj this film i 'm talking about is of course xxmaj alone in the xxmaj dark . i 'll try to take you though a step by step process on why this film was so bad . \n",
              " \n",
              "  xxmaj acting- i 'll first start off with what perhaps was the best xxunk of this film ( next to the ending credits , which played ' xxmaj wish i had xxmaj an xxmaj angel ' , the acting . xxmaj christian xxmaj slater must be proud of himself , he successfully proved that it is possible to act decent in a film worse then drinking xxunk . xxmaj though all his awful dialog he had to speak , it made me wonder why he just did n't walk off the set halfway . xxmaj perhaps it was because of xxmaj stephen xxmaj dorff being in the film as well ( somebody he wishes he could be but fails at it ) . xxmaj tara xxmaj reid is a bad actress but good looking and that 's all that really matters in films like these . xxmaj that is not to say the acting was perfect though , it was average , not good , and perhaps the only thing in the film not good . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj except for ' xxmaj wish i had xxmaj an xxmaj angel ' , the soundtrack is pointless and bad heavy medal being pumped into the viewers ears , perhaps to disguise the awful story ( something i will get to soon ) . a long and very expensive 2 xxup cd soundtrack is now up for sale for those musically challenged . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj directed by xxmaj hollywoods favorite director xxmaj uwe xxmaj ball who brought us the classic xxmaj house of the xxmaj dead . xxmaj telling us \" xxmaj yes , movies can get this utterly bad and that 's just the beginning to my deadly saga of awful movies \" . xxmaj at least it is said to be directed by xxmaj uwe xxmaj ball . xxmaj without being told i would have guessed a monkey was kidnapped from the xxmaj congo , brought here and forced to make opinions on how to make the movie under penalty of being shocked . xxmaj the director of photography was probably a camcorder taped onto a skateboard and pushed forward until it hits a wall . xxmaj on the scenes where the camera should stay still it is constantly moving , not allowing us to stop anywhere and when it should be moving in action , the camera stops for some reason . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj who on earth is stupid enough to put money towards this bomb ? i pity the fool ... sometimes . xxmaj sometimes i 'm glad he or she was taught such a lesson to never put money towards garbage worse then dog dung tied up in a bag . \n",
              " \n",
              "  xxmaj the xxmaj writing / xxmaj xxunk xxmaj trying to xxmaj xxunk the story is more painful then jamming an ice pick under a big toe and kicking a soccer ball as hard as i possibly could with it right after but i will still attempt it . \n",
              " \n",
              "  xxmaj edward xxmaj carnby escapes as a child from an orphanage where 20 children where to go under science experiments . xxmaj he escapes and hides in an electrical outlet where he is electrocuted ( this is the point where it got so bad i started to laugh out loud ) . xxmaj then it fast - forwards many years later where he 's a paranoia detective . xxmaj he get 's attacked by some zombie that ca n't be shot to death , kills it and moves on with life . xxmaj later on he gets attacked by some crazy looking monster and he discovers secrets that nobody else knows . \n",
              " \n",
              "  xxmaj yeah , the plot is bad , really really bad . xxmaj the film beings with expecting us to read approximately 10 minutes , which felt like 100 , of random text about an untrue civilization called the xxmaj xxunk . xxmaj the film goes not to have one twist after another , more then the audience can handle , more then the audience wants to handle , more then the audience could ever care about . xxmaj this storyline is rock bottom bad that even xxmaj double xxmaj dragon does better . \n",
              " \n",
              "  xxmaj overall , miss out on this movie . i gave it a 1 out of 10 but that is because there is no 0 .,xxbos xxmaj geoffrey xxmaj wright , the director of \" xxmaj romper xxmaj stomper \" , transplants xxmaj shakespeare 's \" xxmaj macbeth \" in the contemporary , criminal underworld of xxmaj melbourne , xxmaj australia . xxmaj the result is a semi - awful piece of cinema . xxmaj sam xxmaj xxunk is xxmaj macbeth , and walks around looking very self - conscious and bored . xxmaj victoria xxmaj hill , who wrote the script with xxmaj wright , is xxmaj lady xxmaj macbeth , and she 's neither awful nor good . xxmaj xxunk xxmaj xxunk , who plays xxunk , is the only actor in the cast who exudes any kind of authority . xxmaj the rest , including xxmaj gary xxmaj sweet , are wasted and misdirected . xxmaj shot on xxup hd by the late xxmaj will xxmaj gibson , the movie 's visuals lack character . xxmaj everything is too clean and too deliberately lit . xxmaj wright 's direction is uninspired in the extreme and the action sequences are confusing and inept . xxmaj marketed xxunk as \" the most violent xxmaj australia movie ever \" , the film is violent at times and reasonably bloody , but it fails to deliver a single impactful moment . xxmaj slow moving and terribly pretentious , this umpteenth silver screen version of the classic play is the personification of wrong - headed .,xxbos xxmaj putting the xxup ufo \" thing \" aside . xxmaj this was the best documentary i 've seen . xxmaj factual reporting by xxmaj neil and xxmaj buzz ... a must see . xxmaj the interviews and reporting are a revelation since most of the information was stamped confidential in 1969 and only released in 2006 . xxmaj no documentary to date has the detail or accuracy for such a brief 47 minutes ... xxmaj the xxup facts will blow you away , and you will be left in awe of the risks taken to be the first on the moon ... xxmaj neil and xxmaj buzz are probably the biggest hero 's of our time . xxmaj ever see a man save his own life ? xxmaj bet not . xxmaj neil saves his life when only mili - seconds separated him from death . xxmaj amazing to watch . xxmaj it is a travesty people have not known all the details xxunk with landing on the moon and the courage those men had when facing certain death , from a failing computer ... 10 stars !\n",
              "y: CategoryList\n",
              "positive,negative,negative,negative,positive\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (3000 items)\n",
              "x: TextList\n",
              "xxbos i must admit a slight disappointment with this film ; i had read a lot about how spectacular it was , yet the actual futuristic sequences , the xxmaj age of xxmaj science , take up a very small amount of the film . xxmaj the sets and are excellent when we get to them , and there are some startling images , but this final sequence is lacking in too many other regards ... \n",
              " \n",
              "  xxmaj much the best drama of the piece is in the mid - section , and then it plays as melodrama , arising from the ' high concept ' science - fiction nature of it all , and xxunk robust dialogue . xxmaj there is far more human life in this part though , with the great xxmaj ralph xxmaj richardson sailing gloriously over - the - top as the small dictator , the \" xxmaj boss \" of the xxmaj xxunk . i loved xxmaj richardson 's mannerisms and curt delivery of lines , xxunk the presence and ideas of xxmaj raymond xxmaj massey 's aloof , confident visitor . xxmaj this xxmaj boss is a posturing , convincingly deluded figure , unable to realise the small - fry nature of his kingdom ... xxmaj it 's not a great role , yet xxmaj richardson makes a lot of it . \n",
              " \n",
              "  xxmaj xxunk itself is presumably meant to be xxmaj england , or at least an xxmaj english town fairly representative of xxmaj england . xxmaj interesting was the complete xxunk of any religious side to things ; the ' things to come ' seem to revolve around a conflict between xxunk xxunk and a a faith in science that seems to have little ultimate goal , but to just go on and on . xxmaj there is a belated attempt to raise some arguments and tensions in the last section , concerning more personal ' life ' , yet one is left quite unsatisfied . xxmaj the film has n't got much interest in subtle complexities ; it goes for xxunk spectacle and unsubtle , blunt xxunk , every time . xxmaj and , of course , recall the xxunk - bet finale : xxmaj raymond xxmaj massey xxunk lyrical about how uncertain things are ! \n",
              " \n",
              "  xxmaj concerning the question of the film being a xxunk : i must say it 's not at all bad as such , considering that one obviously allows that it is impossible to gets the details of life anything like right . xxmaj the xxunk xxunk have something to them ; a war in 1940 , well that was perhaps predictable ... xxmaj lasting nearly 30 years , mind ! ? a nuclear bomb - the \" super gun \" or some such xxunk - in 2036 ... a xxunk socialist \" we do n't believe in independent nation xxunk government , in xxmaj britain , after 1970 ... xxmaj hmmm , sadly nowhere near on that one , chaps ! ;-) xxmaj no real politics are gone into here which is a shame ; all that surfaces is a very laudable anti - war sentiment . xxmaj generally , it is assumed that dictatorship - whether xxunk - xxunk - fascist , as under the xxmaj boss , or all - hands - to - the - pump scientific socialism - will * be the deal * , and these implications are not xxunk ... xxmaj while we must remember that in 1936 , there was no knowledge at all of how xxmaj nazism and xxmaj communism would turn out - or even how they were turning out - the lack of consideration of this seems xxunk beside the scope of the filmmakers ' vision on other matters . \n",
              " \n",
              "  xxmaj much of the earlier stuff should - and could - have been cut in my opinion ; only the briefest stuff from ' 1940 ' would have been necessary , yet this segment tends to get rather ponderous , and it is ages before we get to the xxmaj richardson - xxmaj massey parts . i would have liked to have seen more done with xxmaj xxunk xxmaj scott ; who is just a trifle sceptical , cutting a flashing - eyed xxmaj mediterranean figure to negligible purpose . xxmaj the character is not explored , or frankly explained or exploited , except for one scene which i shall not spoil , and her relationship with the xxmaj boss is n't explored ; but then this was the 1930s , and there was such a thing as widespread xxunk censorship back then . xxmaj edward xxmaj chapman is mildly amusing in his two roles ; more so in the first as a hapless chap , praying for war , only to be bluntly put down by another xxmaj massey character . xxmaj massey himself helps things a lot , playing his parts with a mixture of restraint and sombre gusto , contrasting well with a largely xxunk cast , save for xxmaj richardson , and xxmaj scott and xxmaj chapman , slightly . \n",
              " \n",
              "  i would say that \" xxmaj things to xxmaj come \" is undoubtedly a very extraordinary film to have been made in xxmaj britain in 1936 ; one of the few serious xxmaj british science fiction films to date , indeed ! xxmaj its set ( piece ) design and xxunk of resources are ravenous , marvellous . \n",
              " \n",
              "  xxmaj yet , the script is ultimately over - earnest and , at times , all over the place . xxmaj the direction is prone to a xxunk , though it does step up a scenic gear or two upon occasion . xxmaj the cinematographer and xxmaj mr xxmaj richardson really do salvage things however ; respectively creating an awed sense of wonder at technology , and an engaging , jerky performance that consistently xxunk . xxmaj such a shame there is so little substance or real filmic conception to the whole thing ; xxmaj powell and xxmaj xxunk would have been the perfect directors to take on such a task as this - they are without peer among xxmaj british directors as daring visual xxunk , great xxunk of characters and dealers in dialogue of the first rate . \n",
              " \n",
              "  \" xxmaj things to xxmaj come \" , as it stands , is an intriguing oddity , well worth perusing , yet far short of a \" xxmaj metropolis \" ... ' xxmaj xxunk much as \" silly \" , in xxmaj wells ' words , as that xxmaj lang film , yet with nothing like the astonishing force of it .,xxbos i xxup loved this flick when it came out in the 80 's and still do ! i still quote classic lines like \" say it again \" and \" you said you 'd rip my balls off sir \" . xxmaj ron xxmaj xxunk was hot and very funny ! xxmaj although it was underrated and disowned by xxup mad , i have to say that this little gem will always be a treasure of mine and a movie that i would take with me if sent to a deserted island ! i only wish that someone would release the xxup dvd because my xxup vhs tape is about worn out ! xxmaj if you like xxunk out comedy , this is definitely for you and should be considered a cult classic ! xxmaj it is military humor at it 's best and worse ! xxmaj rent it if you ca n't own it !,xxbos whomever thought of having sequels to xxmaj iron xxmaj eagle must be shot . xxmaj in this case once was enough . xxmaj iron xxmaj eagle was a good movie to watch . xxmaj even though it is unrealistic , it is still entertaining . xxmaj iron xxmaj eagle xxup ii has a senseless plot and can be used to as a cure to insomnia . i did n't even bother to watch xxmaj iron xxmaj eagle xxup iii , but from looking at the r rating , i assume it 's more violent than the past 2 movies . xxmaj well , xxmaj iron xxmaj eagle xxup iv is probably the most inane sequel . xxmaj lou xxmaj xxunk xxmaj jr. returns as the always delightful \" xxmaj xxunk \" xxmaj sinclair . xxmaj another xxmaj jason returns to fill the role of xxmaj doug xxmaj masters ( xxmaj canadian xxmaj jason xxmaj xxunk , who looks just like xxmaj jason xxmaj xxunk from the first xxmaj iron xxmaj eagle ) . xxmaj but xxunk comes a possible spoiler ) xxrep 5 . xxmaj was n't xxmaj doug killed in xxmaj iron xxmaj eagle xxup ii ? xxmaj the writers must 've been xxunk for a story so they revived xxmaj doug xxmaj masters by saying he was a prisoner of the xxmaj russians . xxmaj this movie was the cheapest done of all the xxmaj iron xxmaj eagle films . xxmaj why do movie makers find it xxunk to make sequels to unappealing movies ? ( ex . xxmaj police xxmaj academy movies ) . i have always liked xxmaj xxunk xxmaj jr. 's work in these films . xxmaj he was the only one holding this turkey together . xxmaj let 's hope this was the last of the xxmaj iron xxmaj eagle sequels . let it rest in peace .,xxbos i know it 's hard for you xxmaj americans to find xxmaj european films on video / xxup dvd , particularly from the 80 's but please seek out the original version of the xxmaj vanishing - title xxmaj spoorloos ( 1988 ) - and you 'll see why the xxmaj hollywood version of xxmaj the xxmaj vanishing screws up xxunk , particularly at the finale . \n",
              " \n",
              "  i really like xxmaj sandra xxmaj bullock , xxmaj kiefer xxmaj sutherland and particularly xxmaj jeff xxmaj bridges , but this is just so so lame compared with the original . xxmaj what where they thinking ? xxmaj can you imagine xxmaj seven with a happy ending with xxmaj gwyneth xxmaj paltrow running happily into the arms of xxmaj brad xxmaj pitt in the finale ? xxmaj the whole point the original was such a major international success was because of the shocking finale . xxmaj so why do you accept this kind of xxunk remake ? xxmaj really , avoid this and xxup get xxup the xxup original .,xxbos xxmaj we all have seen some unending epics in our times , but this one really tops them all ! xxmaj the movie is so long and so slow , that , just to put things in perspective , i felt a lot older when i left movie hall , than i entered it . xxmaj at almost 4 hours length , it could have rather been made into a tele - serial . \n",
              " \n",
              "  xxmaj what starts as a promising comedy slowly loses its pace . xxmaj nikhil advani has woven the plot around 6 love stories and he ca nt make justice to any one of them ... xxmaj there is no xxunk between them to start with , and links shown in last 20 minutes just seem to be forced to connect the story . \n",
              " \n",
              "  xxmaj situation is made worse by xxmaj silly dialogues ( most of them repeated in xxmaj hindi cinema over xxunk stupid cinematography . \n",
              " \n",
              "  xxmaj priyanka does n't realise that she actually needs to play her role rather than just looking xxunk on screen ... xxmaj an utter waste of beauty without acting skills . \n",
              " \n",
              "  xxmaj and then there is loud - is - humorous xxmaj govinda & my - face - twists - better - than - jim - carrey xxmaj akshay xxmaj khanna who keep belching at the top of their lungs to xxunk already tired viewers . \n",
              " \n",
              "  xxmaj only good part in movie is xxmaj john & xxmaj xxunk 's love story & nice acting / comedy by xxunk & xxmaj xxunk . xxmaj but they are so good at their roles that just these two couples could have justified the movie without xxunk it with other bunch of characters . xxmaj their brilliance gets lost in the midst of other xxunk plot lines . \n",
              " \n",
              "  xxmaj my guess - xxmaj director was making two separate xxunk be more ! ) and some beginner assistant mixed up all the records , beyond a point of xxunk them out , so director was left with no choice to show it all as a single movie ... \n",
              " \n",
              "  xxmaj watch it only if you want to test your patience ! ! !\n",
              "y: CategoryList\n",
              "positive,positive,negative,negative,negative\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(23584, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(23584, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb783c759d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5000 items)\n",
              "x: TextList\n",
              "xxbos \" xxmaj the xxmaj violent xxmaj men \" marked the finest collaboration of xxmaj rudolph xxmaj xxunk with xxmaj glenn xxmaj ford in an intensely satisfying drama of rugged primitive justice \n",
              " \n",
              " \n",
              "  xxmaj ford is xxmaj john xxmaj parrish , a former xxmaj cavalry captain who is xxunk to get married and start a new life \n",
              "  xxmaj his fiancée xxmaj caroline xxmaj xxunk ( xxmaj may xxmaj wynn ) is desperate to move east , and to see him selling his spread to xxmaj lee xxmaj wilkison ( xxmaj edward xxup g. xxmaj robinson ) . \n",
              " \n",
              "  xxmaj parrish is not even much of a xxunk \n",
              "  but he do understand that there is something big building up in the valley \n",
              "  xxmaj in the xxmaj army , they used to call it ' enemy pressure . ' xxmaj first , xxmaj cole xxmaj wilkison ( xxmaj brian xxmaj keith ) comes back from xxmaj texas to help his brother run xxmaj anchor \n",
              "  xxmaj then a tough kid with a fancy gun ( xxmaj richard xxmaj jaeckel ) shows up on the xxmaj wilkison payroll \n",
              "  xxmaj then all the small ranchers are forced out , getting the same kind of offers \n",
              "  xxmaj parrish saw himself either running like they did , or stand and fight \n",
              " \n",
              " \n",
              "  xxmaj but can he easily deals with a man who sends six killers to shoot an old man in the back ? xxmaj can he easily argues with a man who started with a few acres of land and now owns practically the whole valley ? \n",
              " \n",
              "  xxmaj all that grass and sand ever meant to the ex - xxmaj confederate xxmaj army officer the past three years \n",
              "  xxmaj it was a place to regain his health \n",
              "  xxmaj out of habit of taking advice , xxmaj parrish xxunk : \" xxmaj what happen in this valley is no concern of mine . \" xxmaj and much to the disappointment of the remaining ranchers and farmers , who pressure him to stay on , he decides to accept xxmaj wilkison 's offer to fulfill the promise he made to his fiancée \n",
              " \n",
              " \n",
              "  xxmaj when xxmaj lee 's younger brother xxmaj cole made the wrong move , trying to push xxmaj parrish make up his mind by lynching one of his ranch hands , xxmaj parrish got mad and warns the two brothers that he is going to stay and will fight them for the privilege of being let alone \n",
              " \n",
              " \n",
              "  xxmaj brian xxmaj keith plays the traitorous brother who 's behind the killing ... xxmaj he dreams to have position and respect in running one day xxmaj anchor \n",
              " \n",
              " \n",
              "  xxmaj lee 's ambitious wife xxmaj martha ( xxmaj barbara xxmaj stanwyck ) secretly hates herself and her husband \n",
              "  xxmaj stanwyck plays the part of a loving wife who ca n't bear the touch of her husband 's hands \n",
              " \n",
              " \n",
              "  xxmaj edward xxup g. xxmaj robinson is good enough as the xxmaj anchor 's crippled owner who promised the whole valley to his wife , unaware that she is having an affair with his younger brother \n",
              " \n",
              " \n",
              "  xxmaj dianne xxmaj foster is too sensitive as the xxunk adult daughter well aware of her mother 's burdens \n",
              " \n",
              " \n",
              "  \" xxmaj the xxmaj violent xxmaj men \" uses the wide - screen technology to emphasize the scope and power of this harrowing action - drama , making it a perfect example of the genre 's most enduring classics \n",
              ",xxbos xxmaj plants in an ancient xxmaj mayan pyramid structure killing all who come close . xxmaj yes it is weird , as the travelers do not figure it out until everything starts doing crazy . xxmaj and in a movie like this , i just wished it went absurd and had marching bands being attacked by plants wielding xxunk . \n",
              " \n",
              "  xxmaj anyway , a group of people from xxmaj america vacation and go into the mountains with a couple of other newly made xxmaj german friends who know about the place . xxmaj when they get there , xxmaj mayans began shouting at them and hide on the structure . xxmaj and when there , that s when the plants decide to take them out , mimicking cell phone noises , humans , and ancient xxmaj mayan dead people . \n",
              " \n",
              "  xxmaj nothing was really scary about the movie and was not even entertaining . xxmaj not even the weird ending could save this piece of crap . i kept looking for something really good to happen , but nothing . xxmaj oh well . \" f \",xxbos xxmaj true , there are many movies much worse then this movie . xxmaj this movie was no xxmaj manos : xxmaj the xxmaj hands of xxmaj fate , or xxmaj troll 2 ( yes , i have seen them both .. twice ) but at the same time this movie is xxmaj no xxmaj alien , xxmaj predator or even xxmaj alien xxmaj vs . xxmaj predator ( xxmaj yes , even that movie surpassed this ) . xxmaj movies like this make xxmaj battlefield xxmaj earth look like a xxmaj star xxmaj wars it is so bad . xxmaj razzie awards lookout , your biggest competition has just arrived in theaters . xxmaj this film i 'm talking about is of course xxmaj alone in the xxmaj dark . i 'll try to take you though a step by step process on why this film was so bad . \n",
              " \n",
              "  xxmaj acting- i 'll first start off with what perhaps was the best xxunk of this film ( next to the ending credits , which played ' xxmaj wish i had xxmaj an xxmaj angel ' , the acting . xxmaj christian xxmaj slater must be proud of himself , he successfully proved that it is possible to act decent in a film worse then drinking xxunk . xxmaj though all his awful dialog he had to speak , it made me wonder why he just did n't walk off the set halfway . xxmaj perhaps it was because of xxmaj stephen xxmaj dorff being in the film as well ( somebody he wishes he could be but fails at it ) . xxmaj tara xxmaj reid is a bad actress but good looking and that 's all that really matters in films like these . xxmaj that is not to say the acting was perfect though , it was average , not good , and perhaps the only thing in the film not good . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj except for ' xxmaj wish i had xxmaj an xxmaj angel ' , the soundtrack is pointless and bad heavy medal being pumped into the viewers ears , perhaps to disguise the awful story ( something i will get to soon ) . a long and very expensive 2 xxup cd soundtrack is now up for sale for those musically challenged . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj directed by xxmaj hollywoods favorite director xxmaj uwe xxmaj ball who brought us the classic xxmaj house of the xxmaj dead . xxmaj telling us \" xxmaj yes , movies can get this utterly bad and that 's just the beginning to my deadly saga of awful movies \" . xxmaj at least it is said to be directed by xxmaj uwe xxmaj ball . xxmaj without being told i would have guessed a monkey was kidnapped from the xxmaj congo , brought here and forced to make opinions on how to make the movie under penalty of being shocked . xxmaj the director of photography was probably a camcorder taped onto a skateboard and pushed forward until it hits a wall . xxmaj on the scenes where the camera should stay still it is constantly moving , not allowing us to stop anywhere and when it should be moving in action , the camera stops for some reason . \n",
              " \n",
              "  xxmaj the xxmaj xxunk xxmaj who on earth is stupid enough to put money towards this bomb ? i pity the fool ... sometimes . xxmaj sometimes i 'm glad he or she was taught such a lesson to never put money towards garbage worse then dog dung tied up in a bag . \n",
              " \n",
              "  xxmaj the xxmaj writing / xxmaj xxunk xxmaj trying to xxmaj xxunk the story is more painful then jamming an ice pick under a big toe and kicking a soccer ball as hard as i possibly could with it right after but i will still attempt it . \n",
              " \n",
              "  xxmaj edward xxmaj carnby escapes as a child from an orphanage where 20 children where to go under science experiments . xxmaj he escapes and hides in an electrical outlet where he is electrocuted ( this is the point where it got so bad i started to laugh out loud ) . xxmaj then it fast - forwards many years later where he 's a paranoia detective . xxmaj he get 's attacked by some zombie that ca n't be shot to death , kills it and moves on with life . xxmaj later on he gets attacked by some crazy looking monster and he discovers secrets that nobody else knows . \n",
              " \n",
              "  xxmaj yeah , the plot is bad , really really bad . xxmaj the film beings with expecting us to read approximately 10 minutes , which felt like 100 , of random text about an untrue civilization called the xxmaj xxunk . xxmaj the film goes not to have one twist after another , more then the audience can handle , more then the audience wants to handle , more then the audience could ever care about . xxmaj this storyline is rock bottom bad that even xxmaj double xxmaj dragon does better . \n",
              " \n",
              "  xxmaj overall , miss out on this movie . i gave it a 1 out of 10 but that is because there is no 0 .,xxbos xxmaj geoffrey xxmaj wright , the director of \" xxmaj romper xxmaj stomper \" , transplants xxmaj shakespeare 's \" xxmaj macbeth \" in the contemporary , criminal underworld of xxmaj melbourne , xxmaj australia . xxmaj the result is a semi - awful piece of cinema . xxmaj sam xxmaj xxunk is xxmaj macbeth , and walks around looking very self - conscious and bored . xxmaj victoria xxmaj hill , who wrote the script with xxmaj wright , is xxmaj lady xxmaj macbeth , and she 's neither awful nor good . xxmaj xxunk xxmaj xxunk , who plays xxunk , is the only actor in the cast who exudes any kind of authority . xxmaj the rest , including xxmaj gary xxmaj sweet , are wasted and misdirected . xxmaj shot on xxup hd by the late xxmaj will xxmaj gibson , the movie 's visuals lack character . xxmaj everything is too clean and too deliberately lit . xxmaj wright 's direction is uninspired in the extreme and the action sequences are confusing and inept . xxmaj marketed xxunk as \" the most violent xxmaj australia movie ever \" , the film is violent at times and reasonably bloody , but it fails to deliver a single impactful moment . xxmaj slow moving and terribly pretentious , this umpteenth silver screen version of the classic play is the personification of wrong - headed .,xxbos xxmaj putting the xxup ufo \" thing \" aside . xxmaj this was the best documentary i 've seen . xxmaj factual reporting by xxmaj neil and xxmaj buzz ... a must see . xxmaj the interviews and reporting are a revelation since most of the information was stamped confidential in 1969 and only released in 2006 . xxmaj no documentary to date has the detail or accuracy for such a brief 47 minutes ... xxmaj the xxup facts will blow you away , and you will be left in awe of the risks taken to be the first on the moon ... xxmaj neil and xxmaj buzz are probably the biggest hero 's of our time . xxmaj ever see a man save his own life ? xxmaj bet not . xxmaj neil saves his life when only mili - seconds separated him from death . xxmaj amazing to watch . xxmaj it is a travesty people have not known all the details xxunk with landing on the moon and the courage those men had when facing certain death , from a failing computer ... 10 stars !\n",
              "y: CategoryList\n",
              "positive,negative,negative,negative,positive\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (3000 items)\n",
              "x: TextList\n",
              "xxbos i must admit a slight disappointment with this film ; i had read a lot about how spectacular it was , yet the actual futuristic sequences , the xxmaj age of xxmaj science , take up a very small amount of the film . xxmaj the sets and are excellent when we get to them , and there are some startling images , but this final sequence is lacking in too many other regards ... \n",
              " \n",
              "  xxmaj much the best drama of the piece is in the mid - section , and then it plays as melodrama , arising from the ' high concept ' science - fiction nature of it all , and xxunk robust dialogue . xxmaj there is far more human life in this part though , with the great xxmaj ralph xxmaj richardson sailing gloriously over - the - top as the small dictator , the \" xxmaj boss \" of the xxmaj xxunk . i loved xxmaj richardson 's mannerisms and curt delivery of lines , xxunk the presence and ideas of xxmaj raymond xxmaj massey 's aloof , confident visitor . xxmaj this xxmaj boss is a posturing , convincingly deluded figure , unable to realise the small - fry nature of his kingdom ... xxmaj it 's not a great role , yet xxmaj richardson makes a lot of it . \n",
              " \n",
              "  xxmaj xxunk itself is presumably meant to be xxmaj england , or at least an xxmaj english town fairly representative of xxmaj england . xxmaj interesting was the complete xxunk of any religious side to things ; the ' things to come ' seem to revolve around a conflict between xxunk xxunk and a a faith in science that seems to have little ultimate goal , but to just go on and on . xxmaj there is a belated attempt to raise some arguments and tensions in the last section , concerning more personal ' life ' , yet one is left quite unsatisfied . xxmaj the film has n't got much interest in subtle complexities ; it goes for xxunk spectacle and unsubtle , blunt xxunk , every time . xxmaj and , of course , recall the xxunk - bet finale : xxmaj raymond xxmaj massey xxunk lyrical about how uncertain things are ! \n",
              " \n",
              "  xxmaj concerning the question of the film being a xxunk : i must say it 's not at all bad as such , considering that one obviously allows that it is impossible to gets the details of life anything like right . xxmaj the xxunk xxunk have something to them ; a war in 1940 , well that was perhaps predictable ... xxmaj lasting nearly 30 years , mind ! ? a nuclear bomb - the \" super gun \" or some such xxunk - in 2036 ... a xxunk socialist \" we do n't believe in independent nation xxunk government , in xxmaj britain , after 1970 ... xxmaj hmmm , sadly nowhere near on that one , chaps ! ;-) xxmaj no real politics are gone into here which is a shame ; all that surfaces is a very laudable anti - war sentiment . xxmaj generally , it is assumed that dictatorship - whether xxunk - xxunk - fascist , as under the xxmaj boss , or all - hands - to - the - pump scientific socialism - will * be the deal * , and these implications are not xxunk ... xxmaj while we must remember that in 1936 , there was no knowledge at all of how xxmaj nazism and xxmaj communism would turn out - or even how they were turning out - the lack of consideration of this seems xxunk beside the scope of the filmmakers ' vision on other matters . \n",
              " \n",
              "  xxmaj much of the earlier stuff should - and could - have been cut in my opinion ; only the briefest stuff from ' 1940 ' would have been necessary , yet this segment tends to get rather ponderous , and it is ages before we get to the xxmaj richardson - xxmaj massey parts . i would have liked to have seen more done with xxmaj xxunk xxmaj scott ; who is just a trifle sceptical , cutting a flashing - eyed xxmaj mediterranean figure to negligible purpose . xxmaj the character is not explored , or frankly explained or exploited , except for one scene which i shall not spoil , and her relationship with the xxmaj boss is n't explored ; but then this was the 1930s , and there was such a thing as widespread xxunk censorship back then . xxmaj edward xxmaj chapman is mildly amusing in his two roles ; more so in the first as a hapless chap , praying for war , only to be bluntly put down by another xxmaj massey character . xxmaj massey himself helps things a lot , playing his parts with a mixture of restraint and sombre gusto , contrasting well with a largely xxunk cast , save for xxmaj richardson , and xxmaj scott and xxmaj chapman , slightly . \n",
              " \n",
              "  i would say that \" xxmaj things to xxmaj come \" is undoubtedly a very extraordinary film to have been made in xxmaj britain in 1936 ; one of the few serious xxmaj british science fiction films to date , indeed ! xxmaj its set ( piece ) design and xxunk of resources are ravenous , marvellous . \n",
              " \n",
              "  xxmaj yet , the script is ultimately over - earnest and , at times , all over the place . xxmaj the direction is prone to a xxunk , though it does step up a scenic gear or two upon occasion . xxmaj the cinematographer and xxmaj mr xxmaj richardson really do salvage things however ; respectively creating an awed sense of wonder at technology , and an engaging , jerky performance that consistently xxunk . xxmaj such a shame there is so little substance or real filmic conception to the whole thing ; xxmaj powell and xxmaj xxunk would have been the perfect directors to take on such a task as this - they are without peer among xxmaj british directors as daring visual xxunk , great xxunk of characters and dealers in dialogue of the first rate . \n",
              " \n",
              "  \" xxmaj things to xxmaj come \" , as it stands , is an intriguing oddity , well worth perusing , yet far short of a \" xxmaj metropolis \" ... ' xxmaj xxunk much as \" silly \" , in xxmaj wells ' words , as that xxmaj lang film , yet with nothing like the astonishing force of it .,xxbos i xxup loved this flick when it came out in the 80 's and still do ! i still quote classic lines like \" say it again \" and \" you said you 'd rip my balls off sir \" . xxmaj ron xxmaj xxunk was hot and very funny ! xxmaj although it was underrated and disowned by xxup mad , i have to say that this little gem will always be a treasure of mine and a movie that i would take with me if sent to a deserted island ! i only wish that someone would release the xxup dvd because my xxup vhs tape is about worn out ! xxmaj if you like xxunk out comedy , this is definitely for you and should be considered a cult classic ! xxmaj it is military humor at it 's best and worse ! xxmaj rent it if you ca n't own it !,xxbos whomever thought of having sequels to xxmaj iron xxmaj eagle must be shot . xxmaj in this case once was enough . xxmaj iron xxmaj eagle was a good movie to watch . xxmaj even though it is unrealistic , it is still entertaining . xxmaj iron xxmaj eagle xxup ii has a senseless plot and can be used to as a cure to insomnia . i did n't even bother to watch xxmaj iron xxmaj eagle xxup iii , but from looking at the r rating , i assume it 's more violent than the past 2 movies . xxmaj well , xxmaj iron xxmaj eagle xxup iv is probably the most inane sequel . xxmaj lou xxmaj xxunk xxmaj jr. returns as the always delightful \" xxmaj xxunk \" xxmaj sinclair . xxmaj another xxmaj jason returns to fill the role of xxmaj doug xxmaj masters ( xxmaj canadian xxmaj jason xxmaj xxunk , who looks just like xxmaj jason xxmaj xxunk from the first xxmaj iron xxmaj eagle ) . xxmaj but xxunk comes a possible spoiler ) xxrep 5 . xxmaj was n't xxmaj doug killed in xxmaj iron xxmaj eagle xxup ii ? xxmaj the writers must 've been xxunk for a story so they revived xxmaj doug xxmaj masters by saying he was a prisoner of the xxmaj russians . xxmaj this movie was the cheapest done of all the xxmaj iron xxmaj eagle films . xxmaj why do movie makers find it xxunk to make sequels to unappealing movies ? ( ex . xxmaj police xxmaj academy movies ) . i have always liked xxmaj xxunk xxmaj jr. 's work in these films . xxmaj he was the only one holding this turkey together . xxmaj let 's hope this was the last of the xxmaj iron xxmaj eagle sequels . let it rest in peace .,xxbos i know it 's hard for you xxmaj americans to find xxmaj european films on video / xxup dvd , particularly from the 80 's but please seek out the original version of the xxmaj vanishing - title xxmaj spoorloos ( 1988 ) - and you 'll see why the xxmaj hollywood version of xxmaj the xxmaj vanishing screws up xxunk , particularly at the finale . \n",
              " \n",
              "  i really like xxmaj sandra xxmaj bullock , xxmaj kiefer xxmaj sutherland and particularly xxmaj jeff xxmaj bridges , but this is just so so lame compared with the original . xxmaj what where they thinking ? xxmaj can you imagine xxmaj seven with a happy ending with xxmaj gwyneth xxmaj paltrow running happily into the arms of xxmaj brad xxmaj pitt in the finale ? xxmaj the whole point the original was such a major international success was because of the shocking finale . xxmaj so why do you accept this kind of xxunk remake ? xxmaj really , avoid this and xxup get xxup the xxup original .,xxbos xxmaj we all have seen some unending epics in our times , but this one really tops them all ! xxmaj the movie is so long and so slow , that , just to put things in perspective , i felt a lot older when i left movie hall , than i entered it . xxmaj at almost 4 hours length , it could have rather been made into a tele - serial . \n",
              " \n",
              "  xxmaj what starts as a promising comedy slowly loses its pace . xxmaj nikhil advani has woven the plot around 6 love stories and he ca nt make justice to any one of them ... xxmaj there is no xxunk between them to start with , and links shown in last 20 minutes just seem to be forced to connect the story . \n",
              " \n",
              "  xxmaj situation is made worse by xxmaj silly dialogues ( most of them repeated in xxmaj hindi cinema over xxunk stupid cinematography . \n",
              " \n",
              "  xxmaj priyanka does n't realise that she actually needs to play her role rather than just looking xxunk on screen ... xxmaj an utter waste of beauty without acting skills . \n",
              " \n",
              "  xxmaj and then there is loud - is - humorous xxmaj govinda & my - face - twists - better - than - jim - carrey xxmaj akshay xxmaj khanna who keep belching at the top of their lungs to xxunk already tired viewers . \n",
              " \n",
              "  xxmaj only good part in movie is xxmaj john & xxmaj xxunk 's love story & nice acting / comedy by xxunk & xxmaj xxunk . xxmaj but they are so good at their roles that just these two couples could have justified the movie without xxunk it with other bunch of characters . xxmaj their brilliance gets lost in the midst of other xxunk plot lines . \n",
              " \n",
              "  xxmaj my guess - xxmaj director was making two separate xxunk be more ! ) and some beginner assistant mixed up all the records , beyond a point of xxunk them out , so director was left with no choice to show it all as a single movie ... \n",
              " \n",
              "  xxmaj watch it only if you want to test your patience ! ! !\n",
              "y: CategoryList\n",
              "positive,positive,negative,negative,negative\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(23584, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(23584, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb783c759d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(23584, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(23584, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(23584, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(23584, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghUq_JFBhC4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "4eb81f92-e7b5-427f-a19f-73b6496c1ed3"
      },
      "source": [
        "classifier.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='93' class='' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      59.62% [93/156 16:27<11:09 1.5264]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEr2ND2KhGVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "89028708-515e-4246-8ac7-4557cfa47d62"
      },
      "source": [
        "classifier.fit_one_cycle(1, 2e-2,moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.443901</td>\n",
              "      <td>0.349923</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>47:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDjY5FvkhHkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "d49f3f1a-e900-4aa0-e266-b87d767ec336"
      },
      "source": [
        "classifier.freeze_to(-2)\n",
        "classifier.fit_one_cycle(1,slice(5e-3/2.,5e-3),moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.369030</td>\n",
              "      <td>0.304791</td>\n",
              "      <td>0.871333</td>\n",
              "      <td>55:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP1tBXP8hMe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "70d3360c-cd92-4ba1-e0e2-6ed7dcb3eb59"
      },
      "source": [
        "classifier.unfreeze\n",
        "classifier.fit_one_cycle(1,slice(1e-3/100.,1e-3),moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      20.00% [1/5 47:53<3:11:33]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.311453</td>\n",
              "      <td>0.288302</td>\n",
              "      <td>0.877000</td>\n",
              "      <td>47:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/156 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-61334304171e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, from_embeddings)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mnew_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnew_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#To avoid the warning that comes because the weights aren't flattened.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_cka1GbhPXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa60a9b0-85ea-4f82-a476-359d8587c730"
      },
      "source": [
        "classifier.predict(\"This was a great movie\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.0675, 0.9325]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-BpetcoIPSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "daeedf56-6e32-4b0b-91ab-600f440ff599"
      },
      "source": [
        "learner.predict(\"Movie is about the \",n_words=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Movie is about the  same variety of events the world is conducted , with'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKkJrrmA7x4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.export(\"export_classifier.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}